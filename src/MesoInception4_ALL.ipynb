{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.python.keras import optimizers\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.utils.layer_utils import print_summary\n",
    "from tensorflow.python.keras.models import Model as KerasModel\n",
    "from tensorflow.python.keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Dropout, Reshape, Concatenate, LeakyReLU\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from pprint import pprint\n",
    "random.seed(32)\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\" # Choose GPU NUMBERS [0, 1, 2, 3]\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def generate_generator_multiple(generator,dir1, dir2,dir3,dir4,dir5, batch_size, img_height,img_width):\n",
    "    genX1 = generator.flow_from_directory(dir1,\n",
    "                                          target_size = (img_height,img_width),\n",
    "                                          class_mode = 'binary',\n",
    "                                          batch_size = batch_size,\n",
    "                                          shuffle=True, \n",
    "                                          seed=32)   \n",
    "    genX2 = generator.flow_from_directory(dir2,\n",
    "                                          target_size = (img_height,img_width),\n",
    "                                          class_mode = 'binary',\n",
    "                                          batch_size = batch_size,\n",
    "                                          shuffle=True, \n",
    "                                          seed=32)\n",
    "    genX3 = generator.flow_from_directory(dir3,\n",
    "                                          target_size = (img_height,img_width),\n",
    "                                          class_mode = 'binary',\n",
    "                                          batch_size = batch_size,\n",
    "                                          shuffle=True, \n",
    "                                          seed=32)\n",
    "    genX4 = generator.flow_from_directory(dir4,\n",
    "                                          target_size = (img_height,img_width),\n",
    "                                          class_mode = 'binary',\n",
    "                                          batch_size = batch_size,\n",
    "                                          shuffle=True, \n",
    "                                          seed=32)\n",
    "    genX5 = generator.flow_from_directory(dir5,\n",
    "                                          target_size = (img_height,img_width),\n",
    "                                          class_mode = 'binary',\n",
    "                                          batch_size = batch_size,\n",
    "                                          shuffle=True, \n",
    "                                          seed=32)\n",
    "#     for i in range(0,len(genX1.filepaths)+len(genX2.filepaths)):\n",
    "    i=0\n",
    "    while(True):\n",
    "        if i<len(genX1.filepaths):\n",
    "            X1i = genX1.next()\n",
    "            yield X1i[0], X1i[1]\n",
    "            \n",
    "        if i<len(genX2.filepaths):\n",
    "            X2i = genX2.next()\n",
    "            yield X2i[0], X2i[1] \n",
    "            \n",
    "        if i<len(genX3.filepaths):\n",
    "            X3i = genX3.next()\n",
    "            yield X3i[0], X3i[1]\n",
    "            \n",
    "        if i<len(genX4.filepaths):\n",
    "            X4i = genX4.next()\n",
    "            yield X4i[0], X4i[1] \n",
    "            \n",
    "        if i<len(genX5.filepaths):\n",
    "            X5i = genX5.next()\n",
    "            yield X5i[0], X5i[1]\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "img_height=128\n",
    "img_width=128\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator=generate_generator_multiple(generator=train_datagen,\n",
    "                                           dir1='/media/data1/sha/CLRNet/DeepFake/train',\n",
    "                                           dir2='/media/data1/sha/CLRNet/FaceSwap/train',\n",
    "                                           dir3='/media/data1/sha/CLRNet/Face2Face/train',\n",
    "                                           dir4='/media/data1/sha/CLRNet/NeuralTextures/train',\n",
    "                                           dir5='/media/data1/sha/CLRNet/DeepFakeDetection/train',\n",
    "                                           batch_size=batch_size,\n",
    "                                           img_height=img_height,\n",
    "                                           img_width=img_width)    \n",
    "validation_generator=generate_generator_multiple(validation_datagen,\n",
    "                                          dir1='/media/data1/sha/CLRNet/DeepFake/val',\n",
    "                                          dir2='/media/data1/sha/CLRNet/FaceSwap/val',\n",
    "                                          dir3='/media/data1/sha/CLRNet/Face2Face/val',\n",
    "                                          dir4='/media/data1/sha/CLRNet/NeuralTextures/val',\n",
    "                                          dir5='/media/data1/sha/CLRNet/DeepFakeDetection/val',\n",
    "                                          batch_size=batch_size,\n",
    "                                          img_height=img_height,\n",
    "                                          img_width=img_width) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x=train_generator.__next__()\n",
    "print(x[1].shape)\n",
    "pprint(x[1])\n",
    "plt.imshow(x[0][1])\n",
    "plt.title(x[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x=validation_generator.__next__()\n",
    "print(x[1].shape)\n",
    "pprint(x[1])\n",
    "plt.imshow(x[0][1])\n",
    "plt.title(x[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_pred(predictions):\n",
    "    pred=[]\n",
    "    for p in predictions:\n",
    "        if p<0.50:\n",
    "             pred.append(0)\n",
    "        else:\n",
    "            pred.append(1)\n",
    "    return pred\n",
    "\n",
    "IMGWIDTH = 128\n",
    "\n",
    "class Classifier:\n",
    "    def __init__(self):\n",
    "        self.model = 0\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.model.predict(x)\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        return self.model.train_on_batch(x, y)\n",
    "    \n",
    "    def get_accuracy(self, x, y):\n",
    "        return self.model.test_on_batch(x, y)\n",
    "    \n",
    "    def load(self, path):\n",
    "        self.model.load_weights(path)\n",
    "\n",
    "\n",
    "class MesoInception4(Classifier):\n",
    "    def __init__(self, learning_rate = 0.001):\n",
    "        self.model = self.init_model()\n",
    "        optimizer = Adam(lr = learning_rate)\n",
    "        self.model.compile(optimizer = optimizer, loss = 'mean_squared_error', metrics = ['accuracy'])\n",
    "    \n",
    "    def InceptionLayer(self, a, b, c, d):\n",
    "        def func(x):\n",
    "            x1 = Conv2D(a, (1, 1), padding='same', activation='relu')(x)\n",
    "            \n",
    "            x2 = Conv2D(b, (1, 1), padding='same', activation='relu')(x)\n",
    "            x2 = Conv2D(b, (3, 3), padding='same', activation='relu')(x2)\n",
    "            \n",
    "            x3 = Conv2D(c, (1, 1), padding='same', activation='relu')(x)\n",
    "            x3 = Conv2D(c, (3, 3), dilation_rate = 2, strides = 1, padding='same', activation='relu')(x3)\n",
    "            \n",
    "            x4 = Conv2D(d, (1, 1), padding='same', activation='relu')(x)\n",
    "            x4 = Conv2D(d, (3, 3), dilation_rate = 3, strides = 1, padding='same', activation='relu')(x4)\n",
    "\n",
    "            y = Concatenate(axis = -1)([x1, x2, x3, x4])\n",
    "            \n",
    "            return y\n",
    "        return func\n",
    "    \n",
    "    def init_model(self):\n",
    "        x = Input(shape = (IMGWIDTH, IMGWIDTH, 3))\n",
    "        \n",
    "        x1 = self.InceptionLayer(1, 4, 4, 2)(x)\n",
    "        x1 = BatchNormalization()(x1)\n",
    "        x1 = MaxPooling2D(pool_size=(2, 2), padding='same')(x1)\n",
    "        \n",
    "        x2 = self.InceptionLayer(2, 4, 4, 2)(x1)\n",
    "        x2 = BatchNormalization()(x2)\n",
    "        x2 = MaxPooling2D(pool_size=(2, 2), padding='same')(x2)        \n",
    "        \n",
    "        x3 = Conv2D(16, (5, 5), padding='same', activation = 'relu')(x2)\n",
    "        x3 = BatchNormalization()(x3)\n",
    "        x3 = MaxPooling2D(pool_size=(2, 2), padding='same')(x3)\n",
    "        \n",
    "        x4 = Conv2D(16, (5, 5), padding='same', activation = 'relu')(x3)\n",
    "        x4 = BatchNormalization()(x4)\n",
    "        x4 = MaxPooling2D(pool_size=(4, 4), padding='same')(x4)\n",
    "        \n",
    "        y = Flatten()(x4)\n",
    "        y = Dropout(0.5)(y)\n",
    "        y = Dense(16)(y)\n",
    "        y = LeakyReLU(alpha=0.1)(y)\n",
    "        y = Dropout(0.5)(y)\n",
    "        y = Dense(1, activation = 'sigmoid')(y)\n",
    "\n",
    "        return KerasModel(inputs = x, outputs = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model= MesoInception4().model\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=\"MI4_ALL_Ebest.h5\",\n",
    "    save_weights_only=True,\n",
    "    monitor='val_acc',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "csv_logger = CSVLogger(\"MI4_ALL_train.csv\", append=True, separator=',')\n",
    "print_summary(model, line_length=115, positions=None, print_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "total_train=520000/8 #65,000\n",
    "total_val=84000/8   #12,500\n",
    "model.fit_generator(train_generator,\n",
    "                    verbose=1,\n",
    "                    steps_per_epoch=int(total_train/batch_size),\n",
    "                    epochs=50,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps = int(total_val/batch_size),\n",
    "                    callbacks=[model_checkpoint_callback,csv_logger])\n",
    "model.save_weights(\"MI4_ALL_E50.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model= MesoInception4()\n",
    "# model.load(\"MI4_ALL_Ebest.h5\")\n",
    "# model=model.model\n",
    "# print_summary(model, line_length=115, positions=None, print_fn=None)\n",
    "\n",
    "# # model = load_model('ResNet50(bk)_19-12-11-12_38-150-1.00.hdf5')\n",
    "# # adam_fine = Adam(lr=0.00005, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "# # model.compile(loss='binary_crossentropy',\n",
    "# #                   optimizer=adam_fine,\n",
    "# #                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepFakeDetection Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "model= MesoInception4()\n",
    "model.load(\"MI4_ALL_Ebest.h5\")\n",
    "model=model.model\n",
    "print_summary(model, line_length=115, positions=None, print_fn=None)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'datasets/DeepFakeDetection/test',# this is the target directory\n",
    "        target_size=(128, 128),  # all images will be resized to 150x150\n",
    "        class_mode='binary',\n",
    "        shuffle=False,\n",
    "        seed=32) \n",
    "predictions=model.evaluate_generator(test_generator,verbose=2)\n",
    "print(predictions)\n",
    "predictions=model.predict_generator(test_generator,verbose=2)\n",
    "predicted_classes = get_pred(predictions)\n",
    "true_classes = test_generator.classes\n",
    "report = classification_report(true_classes, predicted_classes, digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepFake Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "model= MesoInception4()\n",
    "model.load(\"MI4_ALL_Ebest.h5\")\n",
    "model=model.model\n",
    "print_summary(model, line_length=115, positions=None, print_fn=None)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'datasets/DeepFake/test',# this is the target directory\n",
    "        target_size=(128, 128),  # all images will be resized to 150x150\n",
    "        class_mode='binary',\n",
    "        shuffle=False,\n",
    "        seed=32) \n",
    "predictions=model.evaluate_generator(test_generator,verbose=2)\n",
    "print(predictions)\n",
    "predictions=model.predict_generator(test_generator,verbose=2)\n",
    "predicted_classes = get_pred(predictions)\n",
    "true_classes = test_generator.classes\n",
    "report = classification_report(true_classes, predicted_classes, digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FaceSwap Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "model= MesoInception4()\n",
    "model.load(\"MI4_ALL_Ebest.h5\")\n",
    "model=model.model\n",
    "print_summary(model, line_length=115, positions=None, print_fn=None)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'datasets/FaceSwap/test',# this is the target directory\n",
    "        target_size=(128,128),  # all images will be resized to 150x150\n",
    "        class_mode='binary',\n",
    "        shuffle=False,\n",
    "        seed=32) \n",
    "predictions=model.evaluate_generator(test_generator,verbose=2)\n",
    "print(predictions)\n",
    "predictions=model.predict_generator(test_generator,verbose=2)\n",
    "predicted_classes = get_pred(predictions)\n",
    "true_classes = test_generator.classes\n",
    "report = classification_report(true_classes, predicted_classes, digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face2Face Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "model= MesoInception4()\n",
    "model.load(\"MI4_ALL_Ebest.h5\")\n",
    "model=model.model\n",
    "print_summary(model, line_length=115, positions=None, print_fn=None)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'datasets/Face2Face/test',# this is the target directory\n",
    "        target_size=(128, 128),  # all images will be resized to 150x150\n",
    "        class_mode='binary',\n",
    "        shuffle=False,\n",
    "        seed=32) \n",
    "predictions=model.evaluate_generator(test_generator,verbose=2)\n",
    "print(predictions)\n",
    "predictions=model.predict_generator(test_generator,verbose=2)\n",
    "predicted_classes = get_pred(predictions)\n",
    "true_classes = test_generator.classes\n",
    "report = classification_report(true_classes, predicted_classes, digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeuralTextures Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "model= MesoInception4()\n",
    "model.load(\"MI4_ALL_Ebest.h5\")\n",
    "model=model.model\n",
    "print_summary(model, line_length=115, positions=None, print_fn=None)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'datasets/NeuralTextures/test',# this is the target directory\n",
    "        target_size=(128, 128),  # all images will be resized to 150x150\n",
    "        class_mode='binary',\n",
    "        shuffle=False,\n",
    "        seed=32) \n",
    "predictions=model.evaluate_generator(test_generator,verbose=2)\n",
    "print(predictions)\n",
    "predictions=model.predict_generator(test_generator,verbose=2)\n",
    "predicted_classes = get_pred(predictions)\n",
    "true_classes = test_generator.classes\n",
    "report = classification_report(true_classes, predicted_classes, digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepFakewild Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "model= MesoInception4()\n",
    "model.load(\"MI4_ALL_Ebest.h5\")\n",
    "model=model.model\n",
    "print_summary(model, line_length=115, positions=None, print_fn=None)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'datasets/DeepFakewild/test',# this is the target directory\n",
    "        target_size=(128, 128),  # all images will be resized to 150x150\n",
    "        class_mode='binary',\n",
    "        shuffle=False,\n",
    "        seed=32) \n",
    "predictions=model.evaluate_generator(test_generator,verbose=2)\n",
    "print(predictions)\n",
    "predictions=model.predict_generator(test_generator,verbose=2)\n",
    "predicted_classes = get_pred(predictions)\n",
    "true_classes = test_generator.classes\n",
    "report = classification_report(true_classes, predicted_classes, digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DFDC Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "model= MesoInception4()\n",
    "model.load(\"MI4_ALL_Ebest.h5\")\n",
    "model=model.model\n",
    "print_summary(model, line_length=115, positions=None, print_fn=None)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'datasets/DFDC/test',# this is the target directory\n",
    "        target_size=(128, 128),  # all images will be resized to 150x150\n",
    "        class_mode='binary',\n",
    "        shuffle=False,\n",
    "        seed=32) \n",
    "predictions=model.evaluate_generator(test_generator,verbose=2)\n",
    "print(predictions)\n",
    "predictions=model.predict_generator(test_generator,verbose=2)\n",
    "predicted_classes = get_pred(predictions)\n",
    "true_classes = test_generator.classes\n",
    "report = classification_report(true_classes, predicted_classes, digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New DeepFake wild Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "model= MesoInception4()\n",
    "model.load(\"best_models/MI4_ALL_Ebest.h5\")\n",
    "model=model.model\n",
    "print_summary(model, line_length=115, positions=None, print_fn=None)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'datasets/DFP_new/test',# this is the target directory\n",
    "        target_size=(128, 128),  # all images will be resized to 150x150\n",
    "        class_mode='binary',\n",
    "        shuffle=False,\n",
    "        seed=32) \n",
    "predictions=model.predict_generator(test_generator,verbose=1)\n",
    "predicted_classes = get_pred(predictions)\n",
    "true_classes = test_generator.classes\n",
    "report = classification_report(true_classes, predicted_classes, digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}