{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.python.keras import optimizers\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.python.keras.utils.layer_utils import print_summary\n",
    "from tensorflow.python.keras.models import Model as KerasModel\n",
    "from tensorflow.python.keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Dropout, Reshape, Concatenate, LeakyReLU\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from pprint import pprint\n",
    "random.seed(32)\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\" # Choose GPU NUMBERS [0, 1, 2, 3]\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_generator_multiple(generator,dir1, dir2,dir3,dir4,dir5, batch_size, img_height,img_width):\n",
    "    genX1 = generator.flow_from_directory(dir1,\n",
    "                                          target_size = (img_height,img_width),\n",
    "                                          class_mode = 'categorical',\n",
    "                                          batch_size = batch_size,\n",
    "                                          shuffle=True, \n",
    "                                          seed=32)   \n",
    "    genX2 = generator.flow_from_directory(dir2,\n",
    "                                          target_size = (img_height,img_width),\n",
    "                                          class_mode = 'categorical',\n",
    "                                          batch_size = batch_size,\n",
    "                                          shuffle=True, \n",
    "                                          seed=32)\n",
    "    genX3 = generator.flow_from_directory(dir3,\n",
    "                                          target_size = (img_height,img_width),\n",
    "                                          class_mode = 'categorical',\n",
    "                                          batch_size = batch_size,\n",
    "                                          shuffle=True, \n",
    "                                          seed=32)\n",
    "    genX4 = generator.flow_from_directory(dir4,\n",
    "                                          target_size = (img_height,img_width),\n",
    "                                          class_mode = 'categorical',\n",
    "                                          batch_size = batch_size,\n",
    "                                          shuffle=True, \n",
    "                                          seed=32)\n",
    "    genX5 = generator.flow_from_directory(dir5,\n",
    "                                          target_size = (img_height,img_width),\n",
    "                                          class_mode = 'categorical',\n",
    "                                          batch_size = batch_size,\n",
    "                                          shuffle=True, \n",
    "                                          seed=32)\n",
    "#     for i in range(0,len(genX1.filepaths)+len(genX2.filepaths)):\n",
    "    i=0\n",
    "    while(True):\n",
    "        if i<len(genX1.filepaths):\n",
    "            X1i = genX1.next()\n",
    "            yield X1i[0], X1i[1]\n",
    "            \n",
    "        if i<len(genX2.filepaths):\n",
    "            X2i = genX2.next()\n",
    "            yield X2i[0], X2i[1] \n",
    "            \n",
    "        if i<len(genX3.filepaths):\n",
    "            X3i = genX3.next()\n",
    "            yield X3i[0], X3i[1]\n",
    "            \n",
    "        if i<len(genX4.filepaths):\n",
    "            X4i = genX4.next()\n",
    "            yield X4i[0], X4i[1] \n",
    "            \n",
    "        if i<len(genX5.filepaths):\n",
    "            X5i = genX5.next()\n",
    "            yield X5i[0], X5i[1]\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "batch_size=200\n",
    "img_height=128\n",
    "img_width=128\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator=generate_generator_multiple(generator=train_datagen,\n",
    "                                           dir1='datasets/DeepFake/train',\n",
    "                                           dir2='datasets/FaceSwap/train',\n",
    "                                           dir3='datasets/Face2Face/train',\n",
    "                                           dir4='datasets/NeuralTextures/train',\n",
    "                                           dir5='datasets/DeepFakeDetection/train',\n",
    "                                           batch_size=batch_size,\n",
    "                                           img_height=img_height,\n",
    "                                           img_width=img_width)    \n",
    "validation_generator=generate_generator_multiple(validation_datagen,\n",
    "                                          dir1='datasets/DeepFake/val',\n",
    "                                          dir2='datasets/FaceSwap/val',\n",
    "                                          dir3='datasets/Face2Face/val',\n",
    "                                          dir4='datasets/NeuralTextures/val',\n",
    "                                          dir5='datasets/DeepFakeDetection/val',\n",
    "                                          batch_size=batch_size,\n",
    "                                          img_height=img_height,\n",
    "                                          img_width=img_width) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=train_generator.__next__()\n",
    "print(x[1].shape)\n",
    "pprint(x[1])\n",
    "plt.imshow(x[0][1])\n",
    "plt.title(x[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x=validation_generator.__next__()\n",
    "print(x[1].shape)\n",
    "pprint(x[1])\n",
    "plt.imshow(x[0][1])\n",
    "plt.title(x[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input_tensor = Input(shape=(128, 128, 3))\n",
    "model=tf.keras.applications.Xception(input_tensor=input_tensor,\n",
    "    include_top=True, weights=None, classes=2)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr=0.00005, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False),\n",
    "              metrics=['accuracy'])\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=\"XCE_ALL_Ebest.h5\",\n",
    "    save_weights_only=True,\n",
    "    monitor='val_acc',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "csv_logger = CSVLogger(\"XCE_ALL_train.csv\", append=True, separator=',')\n",
    "print_summary(model, line_length=150, positions=None, print_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "total_train=520000/8 #65,000\n",
    "total_val=84000/8   #10,500\n",
    "model.fit_generator(train_generator,\n",
    "                    verbose=1,\n",
    "                    steps_per_epoch=int(total_train/batch_size),\n",
    "                    epochs=50,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps = int(total_val/batch_size),\n",
    "                    callbacks=[model_checkpoint_callback,csv_logger])\n",
    "model.save_weights(\"XCE_ALL_E50.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepFakeDetection Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "input_tensor = Input(shape=(128, 128, 3))\n",
    "model=tf.keras.applications.Xception(input_tensor=input_tensor,\n",
    "    include_top=True, weights=None, classes=2)\n",
    "model.load_weights(\"XCE_ALL_Ebest.h5\")\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr=0.00005, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False),\n",
    "              metrics=['accuracy'])\n",
    "print_summary(model, line_length=150, positions=None, print_fn=None)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'datasets/DeepFakeDetection/test',# this is the target directory\n",
    "        target_size=(128, 128),  # all images will be resized to 150x150\n",
    "        class_mode='categorical',\n",
    "        shuffle=False,\n",
    "        seed=32) \n",
    "predictions=model.evaluate_generator(test_generator,verbose=2)\n",
    "print(predictions)\n",
    "predictions=model.predict_generator(test_generator,verbose=2)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = test_generator.classes\n",
    "report = classification_report(true_classes, predicted_classes, digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepFake Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "input_tensor = Input(shape=(128, 128, 3))\n",
    "model=tf.keras.applications.Xception(input_tensor=input_tensor,\n",
    "    include_top=True, weights=None, classes=2)\n",
    "model.load_weights(\"XCE_ALL_Ebest.h5\")\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr=0.00005, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False),\n",
    "              metrics=['accuracy'])\n",
    "print_summary(model, line_length=150, positions=None, print_fn=None)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'datasets/DeepFake/test',# this is the target directory\n",
    "        target_size=(128, 128),  # all images will be resized to 150x150\n",
    "        class_mode='categorical',\n",
    "        shuffle=False,\n",
    "        seed=32) \n",
    "predictions=model.evaluate_generator(test_generator,verbose=2)\n",
    "print(predictions)\n",
    "predictions=model.predict_generator(test_generator,verbose=2)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = test_generator.classes\n",
    "report = classification_report(true_classes, predicted_classes, digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FaceSwap Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "input_tensor = Input(shape=(128, 128, 3))\n",
    "model=tf.keras.applications.Xception(input_tensor=input_tensor,\n",
    "    include_top=True, weights=None, classes=2)\n",
    "model.load_weights(\"XCE_ALL_Ebest.h5\")\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr=0.00005, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False),\n",
    "              metrics=['accuracy'])\n",
    "print_summary(model, line_length=150, positions=None, print_fn=None)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'datasets/FaceSwap/test',# this is the target directory\n",
    "        target_size=(128, 128),  # all images will be resized to 150x150\n",
    "        class_mode='categorical',\n",
    "        shuffle=False,\n",
    "        seed=32) \n",
    "predictions=model.evaluate_generator(test_generator,verbose=2)\n",
    "print(predictions)\n",
    "predictions=model.predict_generator(test_generator,verbose=2)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = test_generator.classes\n",
    "report = classification_report(true_classes, predicted_classes, digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face2Face Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "input_tensor = Input(shape=(128, 128, 3))\n",
    "model=tf.keras.applications.Xception(input_tensor=input_tensor,\n",
    "    include_top=True, weights=None, classes=2)\n",
    "model.load_weights(\"XCE_ALL_Ebest.h5\")\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr=0.00005, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False),\n",
    "              metrics=['accuracy'])\n",
    "print_summary(model, line_length=150, positions=None, print_fn=None)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'datasets/Face2Face/test',# this is the target directory\n",
    "        target_size=(128, 128),  # all images will be resized to 150x150\n",
    "        class_mode='categorical',\n",
    "        shuffle=False,\n",
    "        seed=32) \n",
    "predictions=model.evaluate_generator(test_generator,verbose=2)\n",
    "print(predictions)\n",
    "predictions=model.predict_generator(test_generator,verbose=2)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = test_generator.classes\n",
    "report = classification_report(true_classes, predicted_classes, digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeuralTextures Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "input_tensor = Input(shape=(128, 128, 3))\n",
    "model=tf.keras.applications.Xception(input_tensor=input_tensor,\n",
    "    include_top=True, weights=None, classes=2)\n",
    "model.load_weights(\"XCE_ALL_Ebest.h5\")\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr=0.00005, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False),\n",
    "              metrics=['accuracy'])\n",
    "print_summary(model, line_length=150, positions=None, print_fn=None)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'datasets/NeuralTextures/test',# this is the target directory\n",
    "        target_size=(128, 128),  # all images will be resized to 150x150\n",
    "        class_mode='categorical',\n",
    "        shuffle=False,\n",
    "        seed=32) \n",
    "predictions=model.evaluate_generator(test_generator,verbose=2)\n",
    "print(predictions)\n",
    "predictions=model.predict_generator(test_generator,verbose=2)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = test_generator.classes\n",
    "report = classification_report(true_classes, predicted_classes, digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepFakewild Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "input_tensor = Input(shape=(128, 128, 3))\n",
    "model=tf.keras.applications.Xception(input_tensor=input_tensor,\n",
    "    include_top=True, weights=None, classes=2)\n",
    "model.load_weights(\"XCE_ALL_Ebest.h5\")\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr=0.00005, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False),\n",
    "              metrics=['accuracy'])\n",
    "print_summary(model, line_length=150, positions=None, print_fn=None)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'datasets/DeepFakewild/test',# this is the target directory\n",
    "        target_size=(128, 128),  # all images will be resized to 150x150\n",
    "        class_mode='categorical',\n",
    "        shuffle=False,\n",
    "        seed=32) \n",
    "predictions=model.evaluate_generator(test_generator,verbose=2)\n",
    "print(predictions)\n",
    "predictions=model.predict_generator(test_generator,verbose=2)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = test_generator.classes\n",
    "report = classification_report(true_classes, predicted_classes, digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DFDC Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "input_tensor = Input(shape=(128, 128, 3))\n",
    "model=tf.keras.applications.Xception(input_tensor=input_tensor,\n",
    "    include_top=True, weights=None, classes=2)\n",
    "model.load_weights(\"XCE_ALL_Ebest.h5\")\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr=0.00005, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False),\n",
    "              metrics=['accuracy'])\n",
    "print_summary(model, line_length=150, positions=None, print_fn=None)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'datasets/DFDC/test',# this is the target directory\n",
    "        target_size=(128, 128),  # all images will be resized to 150x150\n",
    "        class_mode='categorical',\n",
    "        shuffle=False,\n",
    "        seed=32) \n",
    "predictions=model.evaluate_generator(test_generator,verbose=2)\n",
    "print(predictions)\n",
    "predictions=model.predict_generator(test_generator,verbose=2)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = test_generator.classes\n",
    "report = classification_report(true_classes, predicted_classes, digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New DeepFake wild Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "input_tensor = Input(shape=(128, 128, 3))\n",
    "model=tf.keras.applications.Xception(input_tensor=input_tensor,\n",
    "    include_top=True, weights=None, classes=2)\n",
    "model.load_weights(\"best_models/XCE_ALL_Ebest.h5\")\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr=0.00005, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False),\n",
    "              metrics=['accuracy'])\n",
    "print_summary(model, line_length=150, positions=None, print_fn=None)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'datasets/DFP_new/test',# this is the target directory\n",
    "        target_size=(128, 128),  # all images will be resized to 150x150\n",
    "        class_mode='categorical',\n",
    "        shuffle=False,\n",
    "        seed=32) \n",
    "predictions=model.predict_generator(test_generator,verbose=1)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = test_generator.classes\n",
    "report = classification_report(true_classes, predicted_classes, digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}